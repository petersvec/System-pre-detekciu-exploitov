/*
 * Copyright (C) 2017 Lukas Lences
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package tismacore;

import java.util.ArrayList;
import java.util.Date;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Map;
import java.util.Set;
import java.util.logging.Level;
import java.util.logging.Logger;
import tismacore.helpers.Computer;
import tismacore.helpers.TLogger;
import tismacore.helpers.TProperties;
import weka.core.Instances;

/**
 *
 * @author Lukas Lences
 */
public class TimeWindow {
    private final static Logger LOGGER = Logger.getLogger(TLogger.class.getName());
    private static int global_id = 0;
    ArrayList<Netflow> netFlows;
    HashSet<String> uniqueSourceIP;
    HashMap<String, ArrayList<AggregatedNetFlow>> agrNetFlows;    
    Date startTime;
    Date endTime;
    Instances datasetForEM;
    TCluster tcluster;
    ArrayList<Tinstance> tismaInstances;
    int id;
    String filename;

    public void startCinnosti(){
        aggregateFlows();
        prepareDatasetForClustering();
        clusterThisWindow();
    }
    
    TimeWindow(String f, Netflow nf) {
        filename = f;
        id = global_id++;
        uniqueSourceIP = new HashSet<>();
        netFlows = new ArrayList<>();
        netFlows.add(nf);
        uniqueSourceIP.add(nf.sip);
        startTime = nf.date;
        endTime = Computer.getEndTime(startTime, TProperties.timeWindowWidth);
        LOGGER.log(Level.FINE, "New time window created. Start time: " + startTime + " End time: " + endTime);
    }

    void addNetFlow(Netflow nf) {
        netFlows.add(nf);
        uniqueSourceIP.add(nf.sip);
    }

    private void aggregateFlows() {
        LOGGER.log(Level.FINE, "Aggregating netflows.");
        //prvy netflow
        agrNetFlows = new HashMap();
        Netflow nf = netFlows.get(0);
        AggregatedNetFlow agrNf = new AggregatedNetFlow(nf);
        ArrayList<AggregatedNetFlow> listOfAgrFlows = new ArrayList<>();
        listOfAgrFlows.add(agrNf);
        agrNetFlows.put(agrNf.sourceIP, listOfAgrFlows);

        //kazdy dalsi
        for (int i = 1; i < netFlows.size(); i++) {
            nf = netFlows.get(i);
            //ak tam este nie je, vytovri sa novy
            if ((listOfAgrFlows = agrNetFlows.get(nf.sip)) == null) {
                listOfAgrFlows = new ArrayList<>();
                agrNf = new AggregatedNetFlow(nf);
                listOfAgrFlows.add(agrNf);
                agrNetFlows.put(agrNf.sourceIP, listOfAgrFlows);
            } else {
                //ak tam je
                AggregatedNetFlow agrNfInMap = najdiAgregovanyFlow(listOfAgrFlows, nf);
                if (agrNfInMap == null){
                    vytvorNovyAgregovanyFlovAVloz(nf);
                }else {
                    agrNfInMap.update(nf);
                }
            }
        }
    }
    
    private AggregatedNetFlow najdiAgregovanyFlow(ArrayList<AggregatedNetFlow> list, Netflow nf){
        AggregatedNetFlow retVal = null;
        
        for (AggregatedNetFlow af : list){
            if (nf.date.after(af.startTime) && nf.date.before(af.endTime)){
                retVal = af;
            }
        }
        return retVal;
    }
       
    private void vytvorNovyAgregovanyFlovAVloz(Netflow nf){
        ArrayList<AggregatedNetFlow> agrf = agrNetFlows.get(nf.sip);
        AggregatedNetFlow agrNf = new AggregatedNetFlow(nf);
        agrf.add(agrNf);     
    }
    
    private void prepareDatasetForClustering(){
        LOGGER.log(Level.INFO, "Preparing datasets for clustering.");
        datasetForEM = Computer.createInstancesStructureClustering(uniqueSourceIP);
        tismaInstances = new ArrayList<>();
        
        Set<Map.Entry<String, ArrayList<AggregatedNetFlow>>> set = agrNetFlows.entrySet();
        for(Map.Entry<String, ArrayList<AggregatedNetFlow>> entry : set){
            ArrayList<AggregatedNetFlow> agrNetFlows = entry.getValue();
            for(AggregatedNetFlow af : agrNetFlows){
                Tinstance ti = new Tinstance(af, 
                        datasetForEM.attribute(0).indexOfValue(af.sourceIP));
            tismaInstances.add(ti);
            datasetForEM.add(ti.instance);
            }
        }
       // Reader.saveInstancesToFile("DatasetForClustering_TW_" + id + ".arff", datasetForEM);
    }
    
    private void clusterThisWindow(){
        LOGGER.log(Level.FINE, "Starting generating cluster for TW:" + id);
        tcluster = new TCluster(datasetForEM, tismaInstances, id, filename);      
    }
}
