/*
 * Copyright (C) 2017 Lukas Lences
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with this program.  If not, see <http://www.gnu.org/licenses/>.
 */
package tismacore;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.logging.Level;
import java.util.logging.Logger;
import tismacore.helpers.TLogger;
import weka.clusterers.EM;
import weka.core.Instances;
import tismacore.helpers.Computer;
import tismacore.helpers.Reader;
import tismacore.helpers.TProperties;
import weka.core.DenseInstance;
import weka.core.Instance;

/**
 *
 * @author Lukas Lences
 */
public class TCluster {

    private final static Logger LOGGER = Logger.getLogger(TLogger.class.getName());
    int[] numberOfBotnetFlowsInClusterId, numberOfInstancesInClusterId,
            numberOfNetFlowsInClusterId;
    HashSet<String>[] uniqIpAddresses;
    String[] clusterClasses;
    double[][][] features;

    String[] options;
    EM clusterer;
    Instances datasetOut;
    ArrayList<Tinstance> inputTismaInstances;
    int id;
    String filename;

    TCluster(Instances inpuDataset, ArrayList<Tinstance> inTisma,
            int ix, String f) {
        id = ix;
        filename = f;
        inputTismaInstances = inTisma;
        try {
            initialize();
            clusterer.buildClusterer(inpuDataset);
            setAttributes(inputTismaInstances);
      
            if (TProperties.mode.compareTo("train") == 0) {
                setClusterClasses(TProperties.sensitivity);
            }
            createInstances();            
            saveInstances(TProperties.sensitivity);

        } catch (Exception ex) {
            LOGGER.log(Level.SEVERE, null, ex);
        }
    }

    private void initialize() {
        options = new String[4];
        options[0] = "-I";
        options[1] = "100";
        options[2] = "-num-slots";
        options[3] = Integer.toString(TProperties.executionSlots);

        clusterer = new EM();
    }

    private void setAttributes(ArrayList<Tinstance> inputTismaInstances) {
        try {
            datasetOut = Computer.createInstancesStructureForJRIP();

            int numOfClusters = clusterer.numberOfClusters();
            int numAttr = clusterer.getClusterModelsNumericAtts()[0].length;

            numberOfBotnetFlowsInClusterId = new int[numOfClusters];
            numberOfInstancesInClusterId = new int[numOfClusters];
            numberOfNetFlowsInClusterId = new int[numOfClusters];
            clusterClasses = new String[numOfClusters];
            uniqIpAddresses = new HashSet[numOfClusters];
            for (int i = 0; i < numOfClusters; i++) {
                uniqIpAddresses[i] = new HashSet<>();
            }

            for (Tinstance ti : inputTismaInstances) {
                int idKlastra = clusterer.clusterInstance(ti.instance); //id do kotreho klastra patri
                numberOfInstancesInClusterId[idKlastra]++; //mozem zvysit pocet instancii pre ten klaster
                numberOfNetFlowsInClusterId[idKlastra] += ti.aggregatedNetFlow.amounOfNetflows; //taktiez pocet netflowov
                //pridam aj unikatnu ip adresu ak tam este nie je - hashset
                uniqIpAddresses[idKlastra].add(ti.aggregatedNetFlow.sourceIP);
                //pre vypocet pomeru botnetov treba spocitat aj kolko bolo tychto
                if (TProperties.mode.compareTo("train") == 0) {
                    if (ti.aggregatedNetFlow.label.compareToIgnoreCase("botnet") == 0) {
                        numberOfBotnetFlowsInClusterId[idKlastra] += ti.aggregatedNetFlow.amounOfNetflows;
                    }
                }
            }
            /*
        features[idClustra][idAttr][0] - average number of attr
        features[idClustra][idAttr][1] - standard deviation of that number       
             */
            features = new double[numOfClusters][numAttr][2];
            for (int i = 0; i < numOfClusters; i++) {
                for (int j = 0; j < numAttr; j++) {
                    features[i][j] = clusterer.getClusterModelsNumericAtts()[i][j];
                }
            }

        } catch (Exception ex) {
            LOGGER.log(Level.SEVERE, null, ex);
        }

    }

    private void setClusterClasses(Double sensitivity) {
        try {
            for (int i = 0; i < clusterer.numberOfClusters(); i++) {
                double botnetov = new Double(numberOfBotnetFlowsInClusterId[i]);
                double netflowov = new Double(numberOfNetFlowsInClusterId[i]);
                double hranica = netflowov * sensitivity / 100;
                if (botnetov > hranica) {
                    clusterClasses[i] = "botnet";
                } else {
                    clusterClasses[i] = "other";
                }
            }
        } catch (Exception ex) {
            LOGGER.log(Level.SEVERE, null, ex);
        }
    }

    private void createInstances() {
        try {
            for (int i = 0; i < clusterer.numberOfClusters(); i++) {
                Instance nin = createClusterInstance(numberOfInstancesInClusterId[i],
                        numberOfNetFlowsInClusterId[i],
                        uniqIpAddresses[i].size(),
                        features[i],
                        clusterClasses[i]);
                datasetOut.add(nin);
            }
        } catch (Exception ex) {
            Logger.getLogger(TCluster.class.getName()).log(Level.SEVERE, null, ex);
        }
    }

    private Instance createClusterInstance(int numberOfInstancesInClusterId,
            int numberOfNetFlowsInClusterId,
            int uniqIpAddrSize,
            double features[][],
            String label
    ) {
        Instance in = null;
        double[] values = new double[16];

        //nInstancesInCluster
        values[0] = numberOfInstancesInClusterId;
        //nNetFlows
        values[1] = numberOfNetFlowsInClusterId;
        //nSip
        values[2] = uniqIpAddrSize;

        values[3] = features[1][0];
        values[4] = features[1][1];
        values[5] = features[2][0];
        values[6] = features[2][1];
        values[7] = features[3][0];
        values[8] = features[3][1];
        values[9] = features[4][0];
        values[10] = features[4][1];
        values[11] = features[5][0];
        values[12] = features[5][1];
        values[13] = features[6][0];
        values[14] = features[6][1];

        if (TProperties.mode.compareTo("train") == 0) {
            values[15] = datasetOut.attribute(15).indexOfValue(label);
        }

        in = new DenseInstance(1.0, values);
/*
         System.err.print("DEBUG: Features: ");
            for (int j=0; j< values.length; j++)
                System.err.print(values[j] + " , ");
           System.err.println(label);*/

         
        return in;
    }

    private void saveInstances(Double sensitivity) {
        String pathToSave = TProperties.tismaDirectory + "/instances/s" + sensitivity;
        Reader.checkDirectory(pathToSave);
        String[] d = filename.split("/");
        String subname = d[d.length - 1];

        Reader.saveInstancesToFile("s" + sensitivity + "/" + subname + "_TW_" + id + "_cluster_" + sensitivity + ".arff", datasetOut);
    }
}
